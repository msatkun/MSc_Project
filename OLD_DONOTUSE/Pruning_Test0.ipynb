{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOisrCCQdgMEvpEnX4m39uY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msatkun/MSc_Project/blob/testing/Pruning_Test0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resources used for pruning techniques:\n",
        "https://pytorch.org/tutorials/intermediate/pruning_tutorial.html\n",
        "https://colab.research.google.com/drive/1b7aZamr065WPuLpq9C4RU6irB59gbX_K\n",
        "https://towardsdatascience.com/text-classification-with-cnns-in-pytorch-1113df31e79f\n",
        "https://stackoverflow.com/questions/76296352/how-to-fix-tensor-dimensionality-error-on-pytorch\n"
      ],
      "metadata": {
        "id": "XAkWpFfnnY20"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YG0-RpB6dXqN"
      },
      "outputs": [],
      "source": [
        "#import relevant modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.utils.prune as prune\n",
        "\n",
        "#set up device\n",
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# created a simple CNN model using Pytorch\n",
        "class CNN_model0(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, num_filters, output_dim, dropout):\n",
        "    # vocab_size - vocabulary size of the input text\n",
        "    # embedding_dim - dimensions of word embeddings\n",
        "    # num_filters - number of filter in covolutional layers of the output channels\n",
        "    # output_dim - output dimensions that are equivalent to the clases\n",
        "    super(CNN_model0, self).__init__()\n",
        "    #convert text input into word embeddings\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    # create a list of convolutional layers with input channel of one\n",
        "    self.convs = nn.ModuleList([nn.Conv2d(in_channels=1, out_channels=num_filters,\n",
        "                                          kernel_size=(fs, embedding_dim)) for fs in filter_sizes])\n",
        "    # fully connected linear layer\n",
        "    self.fc = nn.Linear(num_filters, output_dim)\n",
        "    # dropout layer\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, text):\n",
        "    embedded = self.embedding(text)\n",
        "    #output = self.fc( )\n",
        "    return output"
      ],
      "metadata": {
        "id": "OczdD5jOvGnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questions?\n",
        "\n",
        "\n",
        "*   if the model is created in tensorflow, do I have to convert the model so I can apply the pruning method which was created in pytorch?\n",
        "*   how do I deal with the weights that I would have applied on tensorflow for a pytorch model?\n",
        "*   why does *embedded.unsqueeze(1)* help with dimensionality errors for the forward method of the code above?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jRPBGMDIr2aV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# apply the pruning method on a model with the weight percentage\n",
        "def apply_pruning(model, pruning_rate):\n",
        "  # empty list to store the model parameters\n",
        "  parameters = []\n",
        "  # loop to go through the list of model parameters\n",
        "  for name, module in model.named_modules():\n",
        "    # check if it is a 2D convolutional layer or a fully connected layer\n",
        "    if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
        "      parameters.append((module, 'weight'))\n",
        "\n",
        "  # Apply pruning to selected parameters\n",
        "  prune.global_unstructured(\n",
        "      parameters,\n",
        "      # prunes weights based on their L1-norm magnitude\n",
        "      # https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.l1_unstructured.html\n",
        "      pruning_method=prune.L1Unstructured,\n",
        "      # percentage of weights to prune\n",
        "      amount=pruning_rate)\n"
      ],
      "metadata": {
        "id": "EaI8uJik2jNE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}